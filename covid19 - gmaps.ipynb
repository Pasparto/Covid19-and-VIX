{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|country|deaths|\n",
      "+-------+------+\n",
      "|     AF|     1|\n",
      "|     AF|     2|\n",
      "|     AF|     4|\n",
      "|     AF|     1|\n",
      "|     AF|     2|\n",
      "|     AF|     3|\n",
      "|     AF|     0|\n",
      "|     AF|     1|\n",
      "|     AF|     4|\n",
      "|     AF|     2|\n",
      "+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as func\n",
    "corona_info_df = spark.read.csv(\"GyPmnAov.csv\", header = \"true\")\n",
    "corona_info_df = corona_info_df.select(func.col(\"geoId\").alias(\"country\") ,\"deaths\")\n",
    "corona_info_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|country|total deaths|\n",
      "+-------+------------+\n",
      "|     US|     51017.0|\n",
      "|     IT|     25969.0|\n",
      "|     ES|     22524.0|\n",
      "|     FR|     22245.0|\n",
      "|     UK|     19506.0|\n",
      "|     BE|      6679.0|\n",
      "|     IR|      5574.0|\n",
      "|     DE|      5500.0|\n",
      "|     CN|      4636.0|\n",
      "|     NL|      4289.0|\n",
      "+-------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corona_info_df = (corona_info_df\n",
    "    .groupBy(\"country\")\n",
    "    .agg(func.sum(\"deaths\").alias(\"total deaths\"))\n",
    "    .sort(\"total deaths\", ascending = False)\n",
    "    )\n",
    "corona_info_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+\n",
      "|country|  latitude| longitude|\n",
      "+-------+----------+----------+\n",
      "|     AD| 42.546245|  1.601554|\n",
      "|     AE| 23.424076| 53.847818|\n",
      "|     AF|  33.93911| 67.709953|\n",
      "|     AG| 17.060816|-61.796428|\n",
      "|     AI| 18.220554|-63.068615|\n",
      "|     AL| 41.153332| 20.168331|\n",
      "|     AM| 40.069099| 45.038189|\n",
      "|     AN| 12.226079|-69.060087|\n",
      "|     AO|-11.202692| 17.873887|\n",
      "|     AQ|-75.250973| -0.071389|\n",
      "+-------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countries_info_df= spark.read.csv(\"geo_countries.csv\", header = \"true\")\n",
    "countries_info_df = countries_info_df.select(\"country\", \"latitude\", \"longitude\")\n",
    "countries_info_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+------------+\n",
      "|country|  latitude| longitude|total deaths|\n",
      "+-------+----------+----------+------------+\n",
      "|     US|  37.09024|-95.712891|     51017.0|\n",
      "|     IT|  41.87194|  12.56738|     25969.0|\n",
      "|     ES| 40.463667|  -3.74922|     22524.0|\n",
      "|     FR| 46.227638|  2.213749|     22245.0|\n",
      "|     BE| 50.503887|  4.469936|      6679.0|\n",
      "|     IR| 32.427908| 53.688046|      5574.0|\n",
      "|     DE| 51.165691| 10.451526|      5500.0|\n",
      "|     CN|  35.86166|104.195397|      4636.0|\n",
      "|     NL| 52.132633|  5.291266|      4289.0|\n",
      "|     BR|-14.235004| -51.92528|      3670.0|\n",
      "+-------+----------+----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_for_goggle = countries_info_df.join(corona_info_df, on = ['country'], how = 'inner')\n",
    "df_for_goggle.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "data_df = df_for_goggle.withColumn(\"latitude\", df_for_goggle[\"latitude\"].cast(FloatType()))\n",
    "data_df = data_df.withColumn(\"longitude\", data_df[\"longitude\"].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+------------+\n",
      "|country|  latitude| longitude|total deaths|\n",
      "+-------+----------+----------+------------+\n",
      "|     US|  37.09024| -95.71289|     51017.0|\n",
      "|     IT|  41.87194|  12.56738|     25969.0|\n",
      "|     ES|  40.46367|  -3.74922|     22524.0|\n",
      "|     FR|  46.22764|  2.213749|     22245.0|\n",
      "|     BE| 50.503887|  4.469936|      6679.0|\n",
      "|     IR|  32.42791| 53.688046|      5574.0|\n",
      "|     DE|  51.16569| 10.451526|      5500.0|\n",
      "|     CN|  35.86166|  104.1954|      4636.0|\n",
      "|     NL| 52.132633|  5.291266|      4289.0|\n",
      "|     BR|-14.235004| -51.92528|      3670.0|\n",
      "|     TR| 38.963745|  35.24332|      2600.0|\n",
      "|     CA| 56.130367|-106.34677|      2302.0|\n",
      "|     SE| 60.128162| 18.643501|      2152.0|\n",
      "|     CH| 46.818188|  8.227512|      1308.0|\n",
      "|     MX|   23.6345|-102.55279|      1221.0|\n",
      "|     PT|  39.39987| -8.224454|       854.0|\n",
      "|     IE|  53.41291|  -8.24389|       829.0|\n",
      "|     IN| 20.593683|  78.96288|       775.0|\n",
      "|     ID| -0.789275|113.921326|       689.0|\n",
      "|     PE| -9.189967| -75.01515|       634.0|\n",
      "+-------+----------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_for_goggle.longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bb3e6a1f78474b8a9ba69e88ebdde8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gmaps.datasets\n",
    "import gmaps\n",
    "import pandas as pd\n",
    "\n",
    "gmaps.configure(api_key = 'AIzaSyDde0NPAfhdZmOW3G598Oly-7y2OlSlFIU')\n",
    "locations = data_df.toPandas()[[\"latitude\",\"longitude\"]]\n",
    "weights_var = data_df.toPandas()[\"total deaths\"]\n",
    "\n",
    "fig = gmaps.figure()\n",
    "heatmap_layer = gmaps.heatmap_layer(locations, weights = weights_var)\n",
    "heatmap_layer.point_radius = 15\n",
    "heatmap_layer.max_intensity = 100000\n",
    "# fig.add_layer(heatmap_layer)\n",
    "fig.add_layer(gmaps.heatmap_layer(locations, weights = weights))\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
